# æ¨ç†æ¨¡å‹æ€è€ƒè¿‡ç¨‹æ£€æµ‹ä¸è¿‡æ»¤æŠ€æœ¯

## ğŸ” æ¨ç†æ¨¡å‹æ€è€ƒè¿‡ç¨‹çš„æ ¼å¼ç‰¹å¾

### å¸¸è§çš„æ€è€ƒæ ‡è®°æ ¼å¼
```python
# ä¸åŒæ¨ç†æ¨¡å‹çš„æ€è€ƒæ ‡è®°æ¨¡å¼
REASONING_PATTERNS = {
    "openai_o1": {
        "start_markers": ["<thinking>", "<thought>", "Let me think", "I need to"],
        "end_markers": ["</thinking>", "</thought>"],
        "inline_patterns": [r"Let me think.*?\.{3,}", r"I need to consider.*?\.{3,}"]
    },
    
    "anthropic_reasoning": {
        "start_markers": ["<reasoning>", "<analysis>", "Let me analyze"],
        "end_markers": ["</reasoning>", "</analysis>"],
        "inline_patterns": [r"Let me analyze.*?\.{3,}", r"I should consider.*?\.{3,}"]
    },
    
    "deepseek_r1": {
        "start_markers": ["<think>", "<reasoning>", "è®©æˆ‘æƒ³æƒ³", "æˆ‘éœ€è¦åˆ†æ"],
        "end_markers": ["</think>", "</reasoning>"],
        "inline_patterns": [r"è®©æˆ‘æƒ³æƒ³.*?\.{3,}", r"æˆ‘éœ€è¦åˆ†æ.*?\.{3,}"]
    },
    
    "qwen_reasoning": {
        "start_markers": ["<æ€è€ƒ>", "<åˆ†æ>", "è®©æˆ‘åˆ†æ", "é¦–å…ˆ"],
        "end_markers": ["</æ€è€ƒ>", "</åˆ†æ>"],
        "inline_patterns": [r"è®©æˆ‘åˆ†æ.*?ç„¶å", r"é¦–å…ˆ.*?æ¥ä¸‹æ¥"]
    },
    
    "general_reasoning": {
        "start_markers": [
            "Let me think", "I need to", "Let me analyze", "Let me consider",
            "è®©æˆ‘æƒ³æƒ³", "è®©æˆ‘åˆ†æ", "æˆ‘éœ€è¦è€ƒè™‘", "é¦–å…ˆåˆ†æ"
        ],
        "end_markers": [
            "Now I'll", "So my answer", "Therefore", "In conclusion",
            "ç°åœ¨æˆ‘", "æ‰€ä»¥æˆ‘çš„ç­”æ¡ˆ", "å› æ­¤", "æ€»ç»“"
        ],
        "inline_patterns": [
            r"Let me think.*?\.{2,}",
            r"I need to.*?\.{2,}",
            r"è®©æˆ‘æƒ³æƒ³.*?\.{2,}",
            r"é¦–å…ˆ.*?ç„¶å.*?æœ€å",
            r"ä».*?è§’åº¦.*?æ¥çœ‹"
        ]
    }
}
```

## ğŸ› ï¸ æ£€æµ‹ä¸è¿‡æ»¤å®ç°

### 1. æ­£åˆ™è¡¨è¾¾å¼æ£€æµ‹å™¨
```python
import re
from typing import List, Tuple, Dict

class ReasoningDetector:
    """æ¨ç†è¿‡ç¨‹æ£€æµ‹å™¨"""
    
    def __init__(self):
        self.patterns = REASONING_PATTERNS
        self.compiled_patterns = self._compile_patterns()
    
    def _compile_patterns(self):
        """ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼"""
        compiled = {}
        for model_type, patterns in self.patterns.items():
            compiled[model_type] = {
                "start_regex": [re.compile(pattern, re.IGNORECASE | re.DOTALL) 
                               for pattern in patterns["start_markers"]],
                "end_regex": [re.compile(pattern, re.IGNORECASE | re.DOTALL) 
                             for pattern in patterns["end_markers"]],
                "inline_regex": [re.compile(pattern, re.IGNORECASE | re.DOTALL) 
                                for pattern in patterns["inline_patterns"]]
            }
        return compiled
    
    def detect_reasoning_blocks(self, text: str) -> List[Dict]:
        """æ£€æµ‹æ¨ç†å—"""
        reasoning_blocks = []
        
        for model_type, patterns in self.compiled_patterns.items():
            # æ£€æµ‹XMLæ ‡ç­¾å¼çš„æ¨ç†å—
            for start_pattern in patterns["start_regex"]:
                for end_pattern in patterns["end_regex"]:
                    # æŸ¥æ‰¾æˆå¯¹çš„å¼€å§‹å’Œç»“æŸæ ‡è®°
                    combined_pattern = f"({start_pattern.pattern}).*?({end_pattern.pattern})"
                    matches = re.finditer(combined_pattern, text, re.IGNORECASE | re.DOTALL)
                    
                    for match in matches:
                        reasoning_blocks.append({
                            "type": "block",
                            "model": model_type,
                            "start": match.start(),
                            "end": match.end(),
                            "content": match.group(),
                            "confidence": 0.9
                        })
            
            # æ£€æµ‹å†…è”æ¨ç†æ¨¡å¼
            for inline_pattern in patterns["inline_regex"]:
                matches = re.finditer(inline_pattern, text)
                for match in matches:
                    reasoning_blocks.append({
                        "type": "inline",
                        "model": model_type,
                        "start": match.start(),
                        "end": match.end(),
                        "content": match.group(),
                        "confidence": 0.7
                    })
        
        # å»é‡å’Œæ’åº
        reasoning_blocks = self._deduplicate_blocks(reasoning_blocks)
        return sorted(reasoning_blocks, key=lambda x: x["start"])
    
    def _deduplicate_blocks(self, blocks: List[Dict]) -> List[Dict]:
        """å»é‡é‡å çš„æ£€æµ‹å—"""
        if not blocks:
            return blocks
        
        # æŒ‰ç½®ä¿¡åº¦å’Œé•¿åº¦æ’åº
        blocks.sort(key=lambda x: (x["confidence"], x["end"] - x["start"]), reverse=True)
        
        deduplicated = []
        for block in blocks:
            # æ£€æŸ¥æ˜¯å¦ä¸å·²æœ‰å—é‡å 
            overlaps = False
            for existing in deduplicated:
                if (block["start"] < existing["end"] and 
                    block["end"] > existing["start"]):
                    overlaps = True
                    break
            
            if not overlaps:
                deduplicated.append(block)
        
        return deduplicated
```

### 2. æ™ºèƒ½è¿‡æ»¤å™¨
```python
class ReasoningFilter:
    """æ¨ç†è¿‡ç¨‹è¿‡æ»¤å™¨"""
    
    def __init__(self):
        self.detector = ReasoningDetector()
        self.filter_modes = {
            "remove": self._remove_reasoning,
            "replace": self._replace_reasoning,
            "hide": self._hide_reasoning,
            "summarize": self._summarize_reasoning
        }
    
    def filter_reasoning(self, text: str, mode: str = "remove") -> str:
        """è¿‡æ»¤æ¨ç†è¿‡ç¨‹"""
        if mode not in self.filter_modes:
            raise ValueError(f"Unknown filter mode: {mode}")
        
        reasoning_blocks = self.detector.detect_reasoning_blocks(text)
        
        if not reasoning_blocks:
            return text  # æ²¡æœ‰æ£€æµ‹åˆ°æ¨ç†è¿‡ç¨‹
        
        return self.filter_modes[mode](text, reasoning_blocks)
    
    def _remove_reasoning(self, text: str, blocks: List[Dict]) -> str:
        """å®Œå…¨ç§»é™¤æ¨ç†è¿‡ç¨‹"""
        # ä»åå¾€å‰åˆ é™¤ï¼Œé¿å…ç´¢å¼•å˜åŒ–
        for block in reversed(blocks):
            text = text[:block["start"]] + text[block["end"]:]
        
        # æ¸…ç†å¤šä½™çš„ç©ºè¡Œ
        text = re.sub(r'\n\s*\n\s*\n', '\n\n', text)
        return text.strip()
    
    def _replace_reasoning(self, text: str, blocks: List[Dict]) -> str:
        """ç”¨å ä½ç¬¦æ›¿æ¢æ¨ç†è¿‡ç¨‹"""
        for block in reversed(blocks):
            replacement = "[æ€è€ƒè¿‡ç¨‹å·²éšè—]"
            text = text[:block["start"]] + replacement + text[block["end"]:]
        
        return text
    
    def _hide_reasoning(self, text: str, blocks: List[Dict]) -> str:
        """ç”¨æŠ˜å æ ‡è®°éšè—æ¨ç†è¿‡ç¨‹"""
        for block in reversed(blocks):
            hidden_content = f"<details><summary>ç‚¹å‡»æŸ¥çœ‹æ€è€ƒè¿‡ç¨‹</summary>\n{block['content']}\n</details>"
            text = text[:block["start"]] + hidden_content + text[block["end"]:]
        
        return text
    
    def _summarize_reasoning(self, text: str, blocks: List[Dict]) -> str:
        """æ€»ç»“æ¨ç†è¿‡ç¨‹"""
        for block in reversed(blocks):
            # ç®€å•çš„æ€»ç»“é€»è¾‘
            summary = self._create_summary(block["content"])
            text = text[:block["start"]] + summary + text[block["end"]:]
        
        return text
    
    def _create_summary(self, reasoning_content: str) -> str:
        """åˆ›å»ºæ¨ç†è¿‡ç¨‹çš„ç®€è¦æ€»ç»“"""
        # æå–å…³é”®è¯å’Œç»“è®º
        lines = reasoning_content.split('\n')
        key_lines = [line.strip() for line in lines 
                    if any(keyword in line.lower() for keyword in 
                          ['therefore', 'conclusion', 'result', 'å› æ­¤', 'ç»“è®º', 'æ‰€ä»¥'])]
        
        if key_lines:
            return f"[æ¨ç†æ€»ç»“: {key_lines[0][:50]}...]"
        else:
            return "[æ¨ç†è¿‡ç¨‹å·²ç®€åŒ–]"
```

### 3. å®æ—¶è¿‡æ»¤ç³»ç»Ÿ
```python
class RealtimeReasoningFilter:
    """å®æ—¶æ¨ç†è¿‡æ»¤ç³»ç»Ÿ"""
    
    def __init__(self):
        self.filter = ReasoningFilter()
        self.cache = {}
    
    async def filter_model_output(self, model_name: str, raw_output: str, 
                                 filter_mode: str = "remove") -> Dict:
        """å®æ—¶è¿‡æ»¤æ¨¡å‹è¾“å‡º"""
        
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"{model_name}:{hash(raw_output)}:{filter_mode}"
        if cache_key in self.cache:
            return self.cache[cache_key]
        
        # æ£€æµ‹æ¨ç†æ¨¡å¼
        reasoning_blocks = self.filter.detector.detect_reasoning_blocks(raw_output)
        
        # è¿‡æ»¤å¤„ç†
        filtered_output = self.filter.filter_reasoning(raw_output, filter_mode)
        
        result = {
            "original": raw_output,
            "filtered": filtered_output,
            "reasoning_detected": len(reasoning_blocks) > 0,
            "reasoning_blocks": reasoning_blocks,
            "filter_mode": filter_mode,
            "model": model_name
        }
        
        # ç¼“å­˜ç»“æœ
        self.cache[cache_key] = result
        
        return result
    
    def get_clean_output(self, model_output_result: Dict) -> str:
        """è·å–æ¸…æ´çš„è¾“å‡º"""
        return model_output_result["filtered"]
    
    def has_reasoning(self, model_output_result: Dict) -> bool:
        """æ£€æŸ¥æ˜¯å¦åŒ…å«æ¨ç†è¿‡ç¨‹"""
        return model_output_result["reasoning_detected"]
```

## ğŸ­ å…«ä»™ä¸“ç”¨è¿‡æ»¤ç³»ç»Ÿ

### é’ˆå¯¹å…«ä»™çš„ç‰¹æ®Šå¤„ç†
```python
class BaxianReasoningFilter:
    """å…«ä»™ä¸“ç”¨æ¨ç†è¿‡æ»¤å™¨"""
    
    def __init__(self):
        self.realtime_filter = RealtimeReasoningFilter()
        self.immortal_configs = {
            "å•æ´å®¾": {"filter_mode": "remove", "max_length": 100},
            "ä½•ä»™å§‘": {"filter_mode": "remove", "max_length": 100},
            "é“æ‹æ": {"filter_mode": "remove", "max_length": 80},
            "æ±‰é’Ÿç¦»": {"filter_mode": "remove", "max_length": 120},
            "è“é‡‡å’Œ": {"filter_mode": "remove", "max_length": 100},
            "å¼ æœè€": {"filter_mode": "remove", "max_length": 150},
            "éŸ©æ¹˜å­": {"filter_mode": "remove", "max_length": 100},
            "æ›¹å›½èˆ…": {"filter_mode": "remove", "max_length": 120}
        }
    
    async def get_clean_immortal_statement(self, immortal: str, 
                                          model_name: str, 
                                          raw_output: str) -> str:
        """è·å–æ¸…æ´çš„ä»™äººå‘è¨€"""
        
        config = self.immortal_configs[immortal]
        
        # è¿‡æ»¤æ¨ç†è¿‡ç¨‹
        filter_result = await self.realtime_filter.filter_model_output(
            model_name, raw_output, config["filter_mode"]
        )
        
        clean_output = filter_result["filtered"]
        
        # é•¿åº¦æ§åˆ¶
        if len(clean_output) > config["max_length"]:
            clean_output = clean_output[:config["max_length"]] + "..."
        
        # è®°å½•æ—¥å¿—
        if filter_result["reasoning_detected"]:
            print(f"âš ï¸  {immortal} çš„è¾“å‡ºåŒ…å«æ¨ç†è¿‡ç¨‹ï¼Œå·²è‡ªåŠ¨è¿‡æ»¤")
        
        return clean_output
    
    async def batch_filter_debate(self, debate_outputs: Dict[str, str]) -> Dict[str, str]:
        """æ‰¹é‡è¿‡æ»¤è¾©è®ºè¾“å‡º"""
        filtered_outputs = {}
        
        for immortal, raw_output in debate_outputs.items():
            if immortal in self.immortal_configs:
                filtered_outputs[immortal] = await self.get_clean_immortal_statement(
                    immortal, "unknown", raw_output
                )
            else:
                filtered_outputs[immortal] = raw_output
        
        return filtered_outputs
```

## ğŸ”§ é›†æˆåˆ°ç°æœ‰ç³»ç»Ÿ

### ä¸å…«ä»™è¾©è®ºç³»ç»Ÿé›†æˆ
```python
class XiantianBaguaWithFiltering:
    """å¸¦è¿‡æ»¤åŠŸèƒ½çš„å…ˆå¤©å…«å¦è¾©è®ºç³»ç»Ÿ"""
    
    def __init__(self):
        self.baxian_filter = BaxianReasoningFilter()
        self.model_caller = ModelCaller()
    
    async def get_filtered_immortal_statement(self, immortal: str, topic: str) -> str:
        """è·å–è¿‡æ»¤åçš„ä»™äººå‘è¨€"""
        
        # è°ƒç”¨æ¨¡å‹
        model_name = self.get_immortal_model(immortal)
        prompt = self.create_immortal_prompt(immortal, topic)
        raw_output = await self.model_caller.call(model_name, prompt)
        
        # è¿‡æ»¤æ¨ç†è¿‡ç¨‹
        clean_output = await self.baxian_filter.get_clean_immortal_statement(
            immortal, model_name, raw_output
        )
        
        return clean_output
    
    async def conduct_filtered_debate(self, topic: str) -> Dict:
        """è¿›è¡Œè¿‡æ»¤åçš„è¾©è®º"""
        bagua_order = ["å•æ´å®¾", "ä½•ä»™å§‘", "é“æ‹æ", "æ±‰é’Ÿç¦»",
                      "è“é‡‡å’Œ", "å¼ æœè€", "éŸ©æ¹˜å­", "æ›¹å›½èˆ…"]
        
        debate_results = {}
        
        for immortal in bagua_order:
            statement = await self.get_filtered_immortal_statement(immortal, topic)
            debate_results[immortal] = statement
            
            print(f"{immortal}: {statement}")
        
        return debate_results
```

## ğŸ’¡ å®é™…æ•ˆæœæ¼”ç¤º

### Beforeï¼ˆåŸå§‹è¾“å‡ºï¼‰ï¼š
```
"è®©æˆ‘åˆ†æä¸€ä¸‹è¿™ä¸ªé—®é¢˜...é¦–å…ˆä»æŠ€æœ¯é¢æ¥çœ‹ï¼Œå½“å‰å¸‚åœºå‘ˆç°å‡ºæ˜æ˜¾çš„çªç ´ä¿¡å·...
æˆ‘éœ€è¦è€ƒè™‘å¤šä¸ªå› ç´ ...ç»è¿‡æ·±å…¥æ€è€ƒï¼Œæˆ‘è®¤ä¸º..."
```

### Afterï¼ˆè¿‡æ»¤åï¼‰ï¼š
```
"å½“å‰å¸‚åœºå‘ˆç°æ˜æ˜¾çªç ´ä¿¡å·ï¼Œå»ºè®®å…³æ³¨ç§‘æŠ€é¾™å¤´è‚¡ã€‚"
```

## ğŸ¯ ä¼˜åŠ¿æ€»ç»“

### æŠ€æœ¯ä¼˜åŠ¿
1. **ç²¾ç¡®æ£€æµ‹** - å¤šç§æ¨¡å¼è¯†åˆ«æ¨ç†è¿‡ç¨‹
2. **çµæ´»è¿‡æ»¤** - æ”¯æŒç§»é™¤ã€æ›¿æ¢ã€éšè—ç­‰æ¨¡å¼
3. **å®æ—¶å¤„ç†** - æ— éœ€é¢„å…ˆçŸ¥é“æ¨¡å‹ç±»å‹
4. **ç¼“å­˜ä¼˜åŒ–** - æé«˜å¤„ç†æ•ˆç‡

### å®ç”¨ä¼˜åŠ¿
1. **ä¿æŒä¸“ä¸š** - å…«ä»™ä¸ä¼šæš´éœ²æç¬‘ç‹¬ç™½
2. **èŠ‚çœæ—¶é—´** - ç”¨æˆ·åªçœ‹ç»“è®º
3. **æå‡ä½“éªŒ** - é¿å…å†—é•¿çš„æ€è€ƒè¿‡ç¨‹
4. **çµæ´»æ§åˆ¶** - å¯é€‰æ‹©æ˜¯å¦æ˜¾ç¤ºæ¨ç†

è¿™æ ·ä½ å°±å¯ä»¥æ”¾å¿ƒä½¿ç”¨ä»»ä½•æ¨ç†æ¨¡å‹äº†ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨è¿‡æ»¤æ‰æ€è€ƒè¿‡ç¨‹ï¼ğŸ­