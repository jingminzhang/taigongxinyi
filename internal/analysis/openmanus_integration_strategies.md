# ç‚¼å¦–å£¶è°ƒç”¨OpenManusé›†æˆæ–¹æ¡ˆ

## ğŸ¯ æ¶æ„è®¾è®¡

```
ç‚¼å¦–å£¶ (Cauldron) â†â†’ OpenManus (çˆ¬è™«æœåŠ¡)
    â†“                      â†“
å¤ªå…¬å¿ƒæ˜“åˆ†æç³»ç»Ÿ        Playwrightçˆ¬è™«å¼•æ“
    â†“                      â†“
å…«ä»™è®ºé“è¾©è®º           Seeking Alphaæ•°æ®
```

## ğŸ”Œ é›†æˆæ–¹å¼

### 1. **HTTP APIè°ƒç”¨** (æ¨è)

#### OpenManusç«¯æä¾›RESTful API
```python
# OpenManusé¡¹ç›®ä¸­
from fastapi import FastAPI
from playwright.async_api import async_playwright

app = FastAPI()

@app.post("/scrape/seekingalpha")
async def scrape_seeking_alpha(request: ScrapeRequest):
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        page = await browser.new_page()
        
        # è®¾ç½®åæ£€æµ‹
        await page.set_extra_http_headers({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)'
        })
        
        await page.goto(request.url)
        content = await page.content()
        await browser.close()
        
        return {"content": content, "status": "success"}
```

#### ç‚¼å¦–å£¶ç«¯è°ƒç”¨
```python
# åœ¨ä½ çš„ç‚¼å¦–å£¶é¡¹ç›®ä¸­
import httpx

class OpenManusClient:
    def __init__(self, base_url: str, api_key: str = None):
        self.base_url = base_url
        self.api_key = api_key
        self.client = httpx.AsyncClient()
    
    async def scrape_seeking_alpha(self, url: str):
        """è°ƒç”¨OpenManusçˆ¬å–Seeking Alpha"""
        headers = {}
        if self.api_key:
            headers['Authorization'] = f'Bearer {self.api_key}'
        
        response = await self.client.post(
            f"{self.base_url}/scrape/seekingalpha",
            json={"url": url},
            headers=headers
        )
        return response.json()

# ä½¿ç”¨ç¤ºä¾‹
openmanus = OpenManusClient("https://openmanus.your-domain.com")
result = await openmanus.scrape_seeking_alpha(
    "https://seekingalpha.com/pr/20162773-ai-device-startup..."
)
```

### 2. **MCPåè®®é›†æˆ** (æœ€ä¼˜é›…)

#### OpenManusä½œä¸ºMCPæœåŠ¡
```python
# OpenManusé¡¹ç›®ä¸­å®ç°MCPæœåŠ¡å™¨
from mcp import MCPServer

class OpenManusMCPServer(MCPServer):
    def __init__(self):
        super().__init__("openmanus-scraper")
        self.register_tool("scrape_seeking_alpha", self.scrape_seeking_alpha)
    
    async def scrape_seeking_alpha(self, url: str, extract_type: str = "article"):
        """MCPå·¥å…·ï¼šçˆ¬å–Seeking Alphaå†…å®¹"""
        # Playwrightçˆ¬è™«é€»è¾‘
        return {
            "url": url,
            "title": extracted_title,
            "content": extracted_content,
            "metadata": metadata
        }
```

#### ç‚¼å¦–å£¶ç«¯é…ç½®
```yaml
# mcp_services.ymlä¸­æ·»åŠ 
services:
  - name: openmanus-scraper
    type: stdio  # æˆ– http
    command: python
    args: ["-m", "openmanus.mcp_server"]
    env:
      OPENMANUS_API_URL: "https://openmanus.your-domain.com"
      OPENMANUS_API_KEY: "${OPENMANUS_API_KEY}"
    dependencies: ["python>=3.9", "playwright"]
    description: "OpenManusç½‘é¡µçˆ¬è™«æœåŠ¡"
```

### 3. **æ¶ˆæ¯é˜Ÿåˆ—å¼‚æ­¥è°ƒç”¨**

#### ä½¿ç”¨Redis/RabbitMQ
```python
# ç‚¼å¦–å£¶ç«¯å‘é€ä»»åŠ¡
import redis
import json

class OpenManusQueue:
    def __init__(self, redis_url: str):
        self.redis = redis.from_url(redis_url)
    
    async def submit_scrape_task(self, url: str, callback_url: str = None):
        """æäº¤çˆ¬è™«ä»»åŠ¡åˆ°é˜Ÿåˆ—"""
        task = {
            "id": generate_task_id(),
            "url": url,
            "type": "seeking_alpha",
            "callback_url": callback_url,
            "timestamp": datetime.utcnow().isoformat()
        }
        
        self.redis.lpush("openmanus:tasks", json.dumps(task))
        return task["id"]
    
    async def get_result(self, task_id: str):
        """è·å–çˆ¬è™«ç»“æœ"""
        result = self.redis.get(f"openmanus:result:{task_id}")
        return json.loads(result) if result else None
```

### 4. **gRPCé«˜æ€§èƒ½è°ƒç”¨**

#### OpenManus gRPCæœåŠ¡
```protobuf
// openmanus.proto
service OpenManusService {
    rpc ScrapeSeekingAlpha(ScrapeRequest) returns (ScrapeResponse);
    rpc GetTaskStatus(TaskRequest) returns (TaskResponse);
}

message ScrapeRequest {
    string url = 1;
    string extract_type = 2;
    map<string, string> options = 3;
}
```

#### ç‚¼å¦–å£¶gRPCå®¢æˆ·ç«¯
```python
import grpc
from openmanus_pb2_grpc import OpenManusServiceStub

class OpenManusGRPCClient:
    def __init__(self, server_address: str):
        self.channel = grpc.aio.insecure_channel(server_address)
        self.stub = OpenManusServiceStub(self.channel)
    
    async def scrape_seeking_alpha(self, url: str):
        request = ScrapeRequest(url=url, extract_type="article")
        response = await self.stub.ScrapeSeekingAlpha(request)
        return response
```

## ğŸ”§ ç‚¼å¦–å£¶ä¸­çš„å…·ä½“é›†æˆ

### 1. **åœ¨N8Nå·¥ä½œæµä¸­é›†æˆ**
```javascript
// N8Nè‡ªå®šä¹‰èŠ‚ç‚¹
{
  "name": "OpenManus Scraper",
  "type": "http-request",
  "url": "https://openmanus.your-domain.com/scrape/seekingalpha",
  "method": "POST",
  "body": {
    "url": "{{$json.article_url}}",
    "extract_type": "full_article"
  }
}
```

### 2. **åœ¨å…«ä»™è®ºé“ä¸­ä½¿ç”¨**
```python
# jixia_academy_clean/core/enhanced_jixia_agents.py
from openmanus_client import OpenManusClient

class EnhancedJixiaAgent:
    def __init__(self):
        self.openmanus = OpenManusClient(
            base_url=os.getenv("OPENMANUS_API_URL"),
            api_key=os.getenv("OPENMANUS_API_KEY")
        )
    
    async def research_topic(self, topic: str):
        """ç ”ç©¶ç‰¹å®šè¯é¢˜ï¼Œä½¿ç”¨OpenManusè·å–æœ€æ–°èµ„è®¯"""
        # æœç´¢ç›¸å…³æ–‡ç« 
        search_urls = await self.search_seeking_alpha(topic)
        
        # æ‰¹é‡çˆ¬å–å†…å®¹
        articles = []
        for url in search_urls[:5]:  # é™åˆ¶æ•°é‡
            content = await self.openmanus.scrape_seeking_alpha(url)
            articles.append(content)
        
        # åˆ†æå†…å®¹å¹¶ç”Ÿæˆè¾©è®ºè§‚ç‚¹
        return self.generate_debate_points(articles)
```

### 3. **åœ¨å¤ªå…¬å¿ƒæ˜“ç³»ç»Ÿä¸­é›†æˆ**
```python
# src/core/xinyi_system.py
class XinyiAnalysisEngine:
    def __init__(self):
        self.openmanus = OpenManusClient(
            base_url=os.getenv("OPENMANUS_API_URL")
        )
    
    async def analyze_market_sentiment(self, symbol: str):
        """åˆ†æå¸‚åœºæƒ…ç»ªï¼Œç»“åˆçˆ¬è™«æ•°æ®"""
        # è·å–Seeking Alphaä¸Šçš„ç›¸å…³åˆ†æ
        articles = await self.get_symbol_analysis(symbol)
        
        # ç»“åˆå¤ªå…¬å¿ƒæ˜“çš„å¦è±¡åˆ†æ
        sentiment_score = self.calculate_sentiment(articles)
        hexagram = self.generate_hexagram(sentiment_score)
        
        return {
            "symbol": symbol,
            "sentiment": sentiment_score,
            "hexagram": hexagram,
            "articles": articles
        }
```

## ğŸš€ éƒ¨ç½²å’Œé…ç½®

### 1. **ç¯å¢ƒå˜é‡é…ç½®**
```bash
# .envæ–‡ä»¶ä¸­æ·»åŠ 
OPENMANUS_API_URL=https://openmanus.your-domain.com
OPENMANUS_API_KEY=your-secret-api-key
OPENMANUS_TIMEOUT=30
OPENMANUS_RETRY_COUNT=3
```

### 2. **Docker Composeé›†æˆ**
```yaml
# docker-compose.yml
version: '3.8'
services:
  cauldron:
    build: .
    environment:
      - OPENMANUS_API_URL=http://openmanus:8000
    depends_on:
      - openmanus
  
  openmanus:
    image: your-registry/openmanus:latest
    ports:
      - "8001:8000"
    environment:
      - PLAYWRIGHT_BROWSERS_PATH=/ms-playwright
```

### 3. **ç›‘æ§å’Œæ—¥å¿—**
```python
# æ·»åŠ ç›‘æ§
import logging
from prometheus_client import Counter, Histogram

openmanus_requests = Counter('openmanus_requests_total', 'Total OpenManus requests')
openmanus_duration = Histogram('openmanus_request_duration_seconds', 'OpenManus request duration')

class MonitoredOpenManusClient(OpenManusClient):
    async def scrape_seeking_alpha(self, url: str):
        openmanus_requests.inc()
        
        with openmanus_duration.time():
            try:
                result = await super().scrape_seeking_alpha(url)
                logging.info(f"Successfully scraped: {url}")
                return result
            except Exception as e:
                logging.error(f"Failed to scrape {url}: {e}")
                raise
```

## ğŸ’¡ æ¨èæ–¹æ¡ˆ

åŸºäºä½ çš„é¡¹ç›®ç‰¹ç‚¹ï¼Œæˆ‘æ¨èï¼š

1. **ä¸»è¦æ–¹æ¡ˆ**: HTTP API + MCPåè®®
2. **å¤‡ç”¨æ–¹æ¡ˆ**: æ¶ˆæ¯é˜Ÿåˆ—ï¼ˆå¤„ç†å¤§é‡ä»»åŠ¡æ—¶ï¼‰
3. **ç›‘æ§**: Prometheus + Grafana
4. **ç¼“å­˜**: Redisç¼“å­˜çˆ¬è™«ç»“æœ

è¿™æ ·æ—¢ä¿æŒäº†æ¶æ„çš„æ¸…æ™°åˆ†ç¦»ï¼Œåˆèƒ½å……åˆ†åˆ©ç”¨OpenManusçš„çˆ¬è™«èƒ½åŠ›ï¼